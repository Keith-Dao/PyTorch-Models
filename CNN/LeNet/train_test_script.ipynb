{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "from typing import Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import torch\n",
    "import torchsummary\n",
    "import torchvision\n",
    "import tqdm.notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "dataset_location: str = \"../data\"\n",
    "batch_size: int = 256\n",
    "train_validation_split: float = 0.7\n",
    "\n",
    "# Torch\n",
    "device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training\n",
    "epochs: int = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Load the MNIST dataset from torchvision and apply padding and normalisation as part of the transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Pad(2),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0.5, 0.5)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_data = torchvision.datasets.MNIST(dataset_location, transform=transform, download=True)\n",
    "train_data, validation_data = torch.utils.data.random_split(train_validation_data, [train_validation_split, 1 - train_validation_split])\n",
    "test_data = torchvision.datasets.MNIST(dataset_location, train=False, transform=transform, download=True)\n",
    "\n",
    "num_classes = len(train_validation_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(dataset: torch.utils.data.Dataset) -> torch.utils.data.DataLoader:\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loader = get_loader(train_data)\n",
    "validation_loader = get_loader(validation_data)\n",
    "test_loader = get_loader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample() -> tuple[torch.Tensor, str]:\n",
    "    data = next(iter(train_loader))\n",
    "    return data[0][0].squeeze(0), train_validation_data.classes[data[1][0]]\n",
    "\n",
    "image, label = get_sample()\n",
    "print(f\"Class: {label}\")\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from original.lenet import LeNet5\n",
    "\n",
    "# Model\n",
    "model = LeNet5().to(device)\n",
    "torchsummary.summary(model, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from original.manual_scheduler import ManualLRScheduler\n",
    "\n",
    "# Optimizer and scheduler\n",
    "learning_rates: list[float] = [5e-4, 2e-4, 1e-4, 5e-5, 1e-5]\n",
    "counts: list[int] = [2, 3, 3, 4]\n",
    "\n",
    "manual_lr_scheduler = ManualLRScheduler(learning_rates, counts)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rates[0])\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, manual_lr_scheduler.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: torch.optim.lr_scheduler,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    accuracy_fn: Callable[[torch.Tensor, torch.Tensor], float],\n",
    "    tqdm_description: str = \"\"\n",
    ") -> tuple[float, float]: \n",
    "    training_loss = training_accuracy = 0\n",
    "    for data, targets in tqdm.tqdm(train_loader, desc=tqdm_description, ncols=100):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        y = torch.nn.functional.one_hot(targets, num_classes).float()\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(data)\n",
    "        loss = loss_fn(y_pred, y).to(\"cpu\")\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Metrics\n",
    "        training_loss += loss.item()\n",
    "        training_accuracy += accuracy_fn(y_pred, targets)\n",
    "    scheduler.step()\n",
    "    return training_loss / len(train_loader.dataset), training_accuracy / len(train_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def validation_step(\n",
    "    model: torch.nn.Module,\n",
    "    validation_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    accuracy_fn: Callable[[torch.Tensor, torch.Tensor], float],\n",
    "    tqdm_description: str = \"\",\n",
    ") -> tuple[float, float]: \n",
    "    validation_loss = validation_accuracy = 0\n",
    "    for data, targets in tqdm.tqdm(validation_loader, desc=tqdm_description, ncols=100):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        y = torch.nn.functional.one_hot(targets, num_classes).float()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(data)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        # Metrics\n",
    "        validation_loss += loss.item()\n",
    "        validation_accuracy += accuracy_fn(y_pred, targets)\n",
    "    return (\n",
    "        validation_loss / len(validation_loader.dataset), \n",
    "        validation_accuracy / len(validation_loader.dataset)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: torch.optim.lr_scheduler,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    train_history: dict[str, list[float]],\n",
    "    validation_loader: torch.utils.data.DataLoader,\n",
    "    validation_history: dict[str, list[float]],\n",
    "    epochs: int,\n",
    "    loss_fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    accuracy_fn: Callable[[torch.Tensor, torch.Tensor], float]\n",
    ") -> None:\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        training_loss, training_accuracy = train_step(\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            train_loader,\n",
    "            loss_fn,\n",
    "            accuracy_fn,\n",
    "            f\"Training epoch {epoch}/{epochs}\"\n",
    "        )\n",
    "        print(f\"Loss: {training_loss:.2f}, Accuracy: {training_accuracy:.2%}\", flush=True)\n",
    "        train_history[\"loss\"].append(training_loss)\n",
    "        train_history[\"accuracy\"].append(training_accuracy)\n",
    "\n",
    "        validation_loss, validation_accuracy = validation_step(\n",
    "            model,\n",
    "            validation_loader,\n",
    "            loss_fn,\n",
    "            accuracy_fn,\n",
    "            f\"Validating epoch {epoch}/{epochs}\"\n",
    "        )\n",
    "        print(f\"Loss: {validation_loss:.2f}, Accuracy: {validation_accuracy:.2%}\", flush=True)\n",
    "        validation_history[\"loss\"].append(validation_loss)\n",
    "        validation_history[\"accuracy\"].append(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = collections.defaultdict(list)\n",
    "validation_history = collections.defaultdict(list)\n",
    "\n",
    "def accuracy_fn(preds: torch.Tensor, targets:torch.Tensor) -> float:\n",
    "    return (torch.argmin(preds, dim=1) == targets).sum().item()\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    train_loader,\n",
    "    train_history,\n",
    "    validation_loader,\n",
    "    validation_history,\n",
    "    epochs,\n",
    "    LeNet5.loss,\n",
    "    accuracy_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(histories: dict[str, dict[str, list[float]]], metric: str):\n",
    "    ax = plt.figure().gca()\n",
    "\n",
    "    for name, history in histories.items():\n",
    "        plt.plot(range(1, len(history[metric]) + 1), history[metric], \".-\", label=name.capitalize())\n",
    "\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric({\"Training\": train_history, \"Validation\": validation_history} , \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric({\"Training\": train_history, \"Validation\": validation_history} , \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = validation_step(model, test_loader, LeNet5.loss, accuracy_fn, \"Testing\")\n",
    "print(f\"Testing Loss: {test_loss:.2f}, Testing accuracy: {test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modern.lenet import LeNet5\n",
    "\n",
    "# Model\n",
    "model = LeNet5().to(device)\n",
    "torchsummary.summary(model, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = collections.defaultdict(list)\n",
    "validation_history = collections.defaultdict(list)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "def accuracy_fn(preds: torch.Tensor, targets:torch.Tensor) -> float:\n",
    "    return (torch.argmax(preds, dim=1) == targets).sum().item()\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    train_loader,\n",
    "    train_history,\n",
    "    validation_loader,\n",
    "    validation_history,\n",
    "    epochs,\n",
    "    loss_fn,\n",
    "    accuracy_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric({\"Training\": train_history, \"Validation\": validation_history} , \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric({\"Training\": train_history, \"Validation\": validation_history} , \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = validation_step(model, test_loader, loss_fn, accuracy_fn, \"Testing\")\n",
    "print(f\"Testing Loss: {test_loss:.2f}, Testing accuracy: {test_accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
