{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchsummary\n",
    "import torchvision\n",
    "\n",
    "from pytorch_models.utils.augments import AddGaussianNoise\n",
    "from pytorch_models.utils.dataset import get_loader, sample_first\n",
    "from pytorch_models.utils.metrics import plot_metric, pretty_print_metrics\n",
    "from pytorch_models.utils.train_validation import train, validate_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_models.CNN.inception_v3 import InceptionV3 as Model\n",
    "from pytorch_models.CNN.inception_v3 import LabelSmoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "dataset_location: str = \"./data\"\n",
    "\n",
    "# Torch\n",
    "device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Constants\n",
    "# Dataset\n",
    "mnist_train_validation_split: float = 0.7\n",
    "mnist_batch_size: int = 32\n",
    "\n",
    "# Training\n",
    "mnist_epochs: int = 10\n",
    "mnist_auxiliary_loss_weight: float = 0.3\n",
    "mnist_learning_rate: float = 1e-4\n",
    "mnist_label_smoothing_factor: float = 1e-4\n",
    "mnist_optimizer_kwargs: dict[str, Any] = {\"weight_decay\": 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(0.1307, 0.3015),\n",
    "        torchvision.transforms.Resize((299, 299), antialias=True),\n",
    "        torchvision.transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_validation_data = torchvision.datasets.MNIST(\n",
    "    dataset_location, transform=mnist_transform, download=True\n",
    ")\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(mnist_train_validation_data)),\n",
    "    train_size=mnist_train_validation_split,\n",
    "    random_state=333,\n",
    "    shuffle=True,\n",
    "    stratify=mnist_train_validation_data.targets,\n",
    ")\n",
    "mnist_train_data = torch.utils.data.Subset(mnist_train_validation_data, train_idx)\n",
    "mnist_validation_data = torch.utils.data.Subset(mnist_train_validation_data, val_idx)\n",
    "\n",
    "mnist_test_data = torchvision.datasets.MNIST(\n",
    "    dataset_location, train=False, transform=mnist_transform, download=True\n",
    ")\n",
    "\n",
    "num_classes = len(mnist_train_validation_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_loader = get_loader(mnist_train_data, mnist_batch_size)\n",
    "mnist_validation_loader = get_loader(mnist_validation_data, mnist_batch_size)\n",
    "mnist_test_loader = get_loader(mnist_test_data, mnist_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = sample_first(mnist_train_loader, mnist_train_validation_data.classes)\n",
    "\n",
    "print(f\"Class: {label}\")\n",
    "image = torch.clamp(\n",
    "    image.permute(1, 2, 0) * 0.3015 + 0.1307, 0, 1\n",
    ")  # Convert to visible image\n",
    "\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "mnist_model = Model(num_classes).to(device)\n",
    "torchsummary.summary(mnist_model, (3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_loss_fn = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "label_smoothed_mnist_loss_fn = LabelSmoothing(\n",
    "    mnist_loss_fn, mnist_label_smoothing_factor\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    mnist_model.parameters(), mnist_learning_rate, **mnist_optimizer_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_history = collections.defaultdict(list)\n",
    "mnist_validation_history = collections.defaultdict(list)\n",
    "\n",
    "mnist_train_metrics = torchmetrics.MetricCollection(\n",
    "    {\n",
    "        \"accuracy\": torchmetrics.Accuracy(\n",
    "            \"multiclass\",\n",
    "            num_classes=num_classes,\n",
    "            average=\"micro\",\n",
    "        ),\n",
    "        \"precision\": torchmetrics.Precision(\n",
    "            \"multiclass\",\n",
    "            num_classes=num_classes,\n",
    "            average=None,\n",
    "        ),\n",
    "        \"recall\": torchmetrics.Recall(\n",
    "            \"multiclass\",\n",
    "            num_classes=num_classes,\n",
    "            average=None,\n",
    "        ),\n",
    "        \"f1 score\": torchmetrics.F1Score(\n",
    "            \"multiclass\",\n",
    "            num_classes=num_classes,\n",
    "            average=None,\n",
    "        ),\n",
    "    }\n",
    ").to(device)\n",
    "mnist_validation_metrics = mnist_train_metrics.clone()\n",
    "\n",
    "train(\n",
    "    mnist_model,\n",
    "    optimizer,\n",
    "    None,\n",
    "    mnist_train_loader,\n",
    "    mnist_train_history,\n",
    "    mnist_validation_loader,\n",
    "    mnist_validation_history,\n",
    "    mnist_epochs,\n",
    "    label_smoothed_mnist_loss_fn,\n",
    "    mnist_train_validation_data.classes,\n",
    "    mnist_train_metrics,\n",
    "    mnist_validation_metrics,\n",
    "    device,\n",
    "    mnist_auxiliary_loss_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(\n",
    "    {\"Training\": mnist_train_history, \"Validation\": mnist_validation_history},\n",
    "    metric=\"loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(\n",
    "    {\"Training\": mnist_train_history, \"Validation\": mnist_validation_history},\n",
    "    metric=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_metrics = mnist_train_metrics.clone()\n",
    "\n",
    "cifar_test_loss = validate_one_epoch(\n",
    "    mnist_model,\n",
    "    mnist_test_loader,\n",
    "    mnist_loss_fn,\n",
    "    num_classes,\n",
    "    mnist_test_metrics,\n",
    "    device,\n",
    "    \"Testing\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_history = {\"loss\": [cifar_test_loss]} | {\n",
    "    metric: [history.to(\"cpu\")]\n",
    "    for metric, history in mnist_test_metrics.compute().items()\n",
    "}\n",
    "\n",
    "pretty_print_metrics(mnist_test_history, mnist_train_validation_data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(333)\n",
    "\n",
    "# Constants\n",
    "# Dataset\n",
    "cifar_train_validation_split: float = 0.7\n",
    "cifar_batch_size: int = 32\n",
    "\n",
    "# Training\n",
    "cifar_epochs: int = 75\n",
    "cifar_auxiliary_loss_weight: float = 0.3\n",
    "cifar_learning_rate: float = 1e-4\n",
    "cifar_label_smoothing_factor: float = 0.1\n",
    "cifar_optimizer_kwargs: dict[str, Any] = {\"weight_decay\": 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.5071, 0.4865, 0.4409], [0.2009, 0.1984, 0.2023]\n",
    "        ),\n",
    "        torchvision.transforms.Resize((299, 299), antialias=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cifar_transforms_with_augmentations = torchvision.transforms.Compose(\n",
    "    [\n",
    "        cifar_transforms,\n",
    "        torchvision.transforms.RandomResizedCrop(299, antialias=True),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        AddGaussianNoise(0, 0.01),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train_data = torchvision.datasets.CIFAR100(\n",
    "    dataset_location, transform=cifar_transforms_with_augmentations, download=True\n",
    ")\n",
    "cifar_validation_data = torchvision.datasets.CIFAR100(\n",
    "    dataset_location, transform=cifar_transforms, download=True\n",
    ")\n",
    "cifar_classes = cifar_train_data.classes\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(cifar_train_data)),\n",
    "    train_size=cifar_train_validation_split,\n",
    "    random_state=333,\n",
    "    shuffle=True,\n",
    "    stratify=cifar_train_data.targets,\n",
    ")\n",
    "cifar_train_data = torch.utils.data.Subset(cifar_train_data, train_idx)\n",
    "cifar_validation_data = torch.utils.data.Subset(cifar_validation_data, val_idx)\n",
    "\n",
    "cifar_test_data = torchvision.datasets.CIFAR100(\n",
    "    dataset_location, False, transform=cifar_transforms, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train_loader = get_loader(cifar_train_data, cifar_batch_size)\n",
    "cifar_validation_loader = get_loader(cifar_validation_data, cifar_batch_size)\n",
    "cifar_test_loader = get_loader(cifar_test_data, cifar_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = sample_first(cifar_train_loader, cifar_classes)\n",
    "\n",
    "print(f\"Class: {label}\")\n",
    "image = torch.clamp(\n",
    "    image.permute(1, 2, 0) * torch.tensor([0.2009, 0.1984, 0.2023])\n",
    "    + torch.tensor([0.5071, 0.4865, 0.4409]),\n",
    "    0,\n",
    "    1,\n",
    ")  # Convert to visible image\n",
    "\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "cifar_model = Model(num_classes).to(device)\n",
    "torchsummary.summary(cifar_model, (3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_loss_fn = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "label_smoothed_cifar_loss_fn = LabelSmoothing(\n",
    "    cifar_loss_fn, cifar_label_smoothing_factor\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    cifar_model.parameters(), cifar_learning_rate, **cifar_optimizer_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train_history = collections.defaultdict(list)\n",
    "cifar_validation_history = collections.defaultdict(list)\n",
    "\n",
    "cifar_train_metrics = torchmetrics.MetricCollection(\n",
    "    {\n",
    "        \"accuracy\": torchmetrics.Accuracy(\n",
    "            \"multiclass\",\n",
    "            num_classes=num_classes,\n",
    "            average=\"micro\",\n",
    "        ),\n",
    "        \"precision\": torchmetrics.Precision(\n",
    "            \"multiclass\",\n",
    "            num_classes=num_classes,\n",
    "            average=None,\n",
    "        ),\n",
    "        \"recall\": torchmetrics.Recall(\n",
    "            \"multiclass\",\n",
    "            num_classes=num_classes,\n",
    "            average=None,\n",
    "        ),\n",
    "        \"f1 score\": torchmetrics.F1Score(\n",
    "            \"multiclass\",\n",
    "            num_classes=num_classes,\n",
    "            average=None,\n",
    "        ),\n",
    "    }\n",
    ").to(device)\n",
    "cifar_validation_metrics = cifar_train_metrics.clone()\n",
    "\n",
    "train(\n",
    "    cifar_model,\n",
    "    optimizer,\n",
    "    None,\n",
    "    cifar_train_loader,\n",
    "    cifar_train_history,\n",
    "    cifar_validation_loader,\n",
    "    cifar_validation_history,\n",
    "    cifar_epochs,\n",
    "    cifar_loss_fn,\n",
    "    cifar_classes,\n",
    "    cifar_train_metrics,\n",
    "    cifar_validation_metrics,\n",
    "    device,\n",
    "    cifar_auxiliary_loss_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(\n",
    "    {\"Training\": cifar_train_history, \"Validation\": cifar_validation_history},\n",
    "    metric=\"loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(\n",
    "    {\"Training\": cifar_train_history, \"Validation\": cifar_validation_history},\n",
    "    metric=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_test_metrics = cifar_train_metrics.clone()\n",
    "\n",
    "cifar_test_loss = validate_one_epoch(\n",
    "    cifar_model,\n",
    "    cifar_test_loader,\n",
    "    cifar_loss_fn,\n",
    "    num_classes,\n",
    "    cifar_test_metrics,\n",
    "    device,\n",
    "    \"Testing\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_test_history = {\"loss\": [cifar_test_loss]} | {\n",
    "    metric: [history.to(\"cpu\")]\n",
    "    for metric, history in cifar_test_metrics.compute().items()\n",
    "}\n",
    "\n",
    "pretty_print_metrics(cifar_test_history, cifar_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
