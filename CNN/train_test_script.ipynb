{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.utils\n",
    "import torchmetrics\n",
    "import torchsummary\n",
    "import torchvision\n",
    "\n",
    "from utils.augments import AddGaussianNoise\n",
    "from utils.dataset import get_loader, sample_first\n",
    "from utils.metrics import plot_metric, pretty_print_metrics\n",
    "from utils.train_validation import train, validate_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Inception_V3.model.inception_v3 import InceptionV3 as model\n",
    "from Inception_V3.regularisation.label_smoothing import LabelSmoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "dataset_location: str = \"./data\"\n",
    "\n",
    "# Torch\n",
    "device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Constants\n",
    "# Dataset\n",
    "mnist_train_validation_split: float = 0.7\n",
    "mnist_batch_size: int = 32\n",
    "\n",
    "# Training\n",
    "mnist_epochs: int = 10\n",
    "mnist_auxiliary_loss_weight: float = 0.3\n",
    "mnist_learning_rate: float = 1e-4\n",
    "mnist_label_smoothing_factor: float = 1e-4\n",
    "mnist_optimizer_kwargs: dict[str, Any] = {\n",
    "    \"weight_decay\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0.1307, 0.3015),\n",
    "    torchvision.transforms.Resize((299, 299), antialias=True), # type: ignore\n",
    "    torchvision.transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_validation_data = torchvision.datasets.MNIST(\n",
    "    dataset_location,\n",
    "    transform=mnist_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(mnist_train_validation_data)), \n",
    "    train_size=mnist_train_validation_split, \n",
    "    random_state=333, \n",
    "    shuffle=True, \n",
    "    stratify=mnist_train_validation_data.targets\n",
    ")\n",
    "mnist_train_data = torch.utils.data.Subset(mnist_train_validation_data, train_idx)\n",
    "mnist_validation_data = torch.utils.data.Subset(mnist_train_validation_data, val_idx)\n",
    "\n",
    "mnist_test_data = torchvision.datasets.MNIST(\n",
    "    dataset_location,\n",
    "    train=False,\n",
    "    transform=mnist_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "num_classes = len(mnist_train_validation_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_loader = get_loader(mnist_train_data, mnist_batch_size)\n",
    "mnist_validation_loader = get_loader(mnist_validation_data, mnist_batch_size)\n",
    "mnist_test_loader = get_loader(mnist_test_data, mnist_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = sample_first(mnist_train_loader, mnist_train_validation_data.classes)\n",
    "\n",
    "print(f\"Class: {label}\")\n",
    "image = torch.clamp(image.permute(1, 2, 0) * 0.3015 + 0.1307, 0, 1) # Convert to visible image\n",
    "\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "mnist_model = model(num_classes).to(device)\n",
    "torchsummary.summary(mnist_model, (3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_loss_fn = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "label_smoothed_mnist_loss_fn = LabelSmoothing(mnist_loss_fn, mnist_label_smoothing_factor)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(mnist_model.parameters(), mnist_learning_rate, **mnist_optimizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_history = collections.defaultdict(list)\n",
    "mnist_validation_history = collections.defaultdict(list)\n",
    "\n",
    "mnist_train_metrics = torchmetrics.MetricCollection({\n",
    "    \"accuracy\": torchmetrics.classification.MulticlassAccuracy(num_classes, average=\"micro\"),\n",
    "    \"precision\": torchmetrics.classification.MulticlassPrecision(num_classes, average=None),\n",
    "    \"recall\": torchmetrics.classification.MulticlassRecall(num_classes, average=None),\n",
    "    \"f1 score\": torchmetrics.classification.MulticlassF1Score(num_classes, average=None),\n",
    "}).to(device)\n",
    "mnist_validation_metrics = mnist_train_metrics.clone()\n",
    "\n",
    "train(\n",
    "    mnist_model,\n",
    "    optimizer,\n",
    "    None,\n",
    "    mnist_train_loader,\n",
    "    mnist_train_history,\n",
    "    mnist_validation_loader,\n",
    "    mnist_validation_history,\n",
    "    mnist_epochs,\n",
    "    label_smoothed_mnist_loss_fn, \n",
    "    mnist_train_validation_data.classes, \n",
    "    mnist_train_metrics,\n",
    "    mnist_validation_metrics,\n",
    "    device,\n",
    "    mnist_auxiliary_loss_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric({\"Training\": mnist_train_history, \"Validation\": mnist_validation_history}, metric=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric({\"Training\": mnist_train_history, \"Validation\": mnist_validation_history}, metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_metrics = mnist_train_metrics.clone()\n",
    "\n",
    "cifar_test_loss = validate_one_epoch(\n",
    "    mnist_model, \n",
    "    mnist_test_loader,\n",
    "    mnist_loss_fn,\n",
    "    num_classes,\n",
    "    mnist_test_metrics,\n",
    "    device,\n",
    "    \"Testing\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_history = {\n",
    "    \"loss\": [cifar_test_loss]\n",
    "} | {metric: [history.to(\"cpu\")] for metric, history in mnist_test_metrics.compute().items()}\n",
    "\n",
    "pretty_print_metrics(mnist_test_history, mnist_train_validation_data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(333)\n",
    "\n",
    "# Constants\n",
    "# Dataset\n",
    "cifar_train_validation_split: float = 0.7\n",
    "cifar_batch_size: int = 32\n",
    "\n",
    "# Training\n",
    "cifar_epochs: int = 75\n",
    "cifar_auxiliary_loss_weight: float = 0.3\n",
    "cifar_learning_rate: float = 1e-4\n",
    "cifar_label_smoothing_factor: float = 0.1\n",
    "cifar_optimizer_kwargs: dict[str, Any] = {\n",
    "    \"weight_decay\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5071, 0.4865, 0.4409], [0.2009, 0.1984, 0.2023]),\n",
    "    torchvision.transforms.Resize((299, 299), antialias=True), # type: ignore\n",
    "])\n",
    "\n",
    "cifar_transforms_with_augmentations = torchvision.transforms.Compose([\n",
    "    cifar_transforms,\n",
    "    torchvision.transforms.RandomResizedCrop(299, antialias=True),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    AddGaussianNoise(0, 0.01),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train_validation_data = torchvision.datasets.CIFAR100(\n",
    "    dataset_location, \n",
    "    transform=cifar_transforms,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(cifar_train_validation_data)), \n",
    "    train_size=cifar_train_validation_split, \n",
    "    random_state=333, \n",
    "    shuffle=True, \n",
    "    stratify=cifar_train_validation_data.targets\n",
    ")\n",
    "cifar_train_data = torch.utils.data.Subset(cifar_train_validation_data, train_idx)\n",
    "cifar_validation_data = torch.utils.data.Subset(cifar_train_validation_data, val_idx)\n",
    "cifar_train_data.dataset.transform = cifar_transforms_with_augmentations\n",
    "\n",
    "cifar_test_data = torchvision.datasets.CIFAR100(\n",
    "    dataset_location,\n",
    "    False,\n",
    "    transform=cifar_transforms,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "num_classes = len(cifar_train_validation_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train_loader = get_loader(cifar_train_data, cifar_batch_size)\n",
    "cifar_validation_loader = get_loader(cifar_validation_data, cifar_batch_size)\n",
    "cifar_test_loader = get_loader(cifar_test_data, cifar_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = sample_first(\n",
    "    cifar_train_loader,\n",
    "    cifar_train_validation_data.classes\n",
    ")\n",
    "\n",
    "print(f\"Class: {label}\")\n",
    "image = torch.clamp(\n",
    "        image.permute(1, 2, 0) \n",
    "        * torch.tensor([0.2009, 0.1984, 0.2023]) \n",
    "        + torch.tensor([0.5071, 0.4865, 0.4409]),\n",
    "        0,\n",
    "        1\n",
    "    ) # Convert to visible image\n",
    "\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "cifar_model = model(num_classes).to(device)\n",
    "torchsummary.summary(cifar_model, (3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_loss_fn = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "label_smoothed_cifar_loss_fn = LabelSmoothing(cifar_loss_fn, cifar_label_smoothing_factor)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(cifar_model.parameters(), cifar_learning_rate, **cifar_optimizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train_history = collections.defaultdict(list)\n",
    "cifar_validation_history = collections.defaultdict(list)\n",
    "\n",
    "cifar_train_metrics = torchmetrics.MetricCollection({\n",
    "    \"accuracy\": torchmetrics.classification.MulticlassAccuracy(num_classes, average=\"micro\"),\n",
    "    \"precision\": torchmetrics.classification.MulticlassPrecision(num_classes, average=None),\n",
    "    \"recall\": torchmetrics.classification.MulticlassRecall(num_classes, average=None),\n",
    "    \"f1 score\": torchmetrics.classification.MulticlassF1Score(num_classes, average=None),\n",
    "}).to(device)\n",
    "cifar_validation_metrics = cifar_train_metrics.clone()\n",
    "\n",
    "train(\n",
    "    cifar_model,\n",
    "    optimizer,\n",
    "    None,\n",
    "    cifar_train_loader,\n",
    "    cifar_train_history,\n",
    "    cifar_validation_loader,\n",
    "    cifar_validation_history,\n",
    "    cifar_epochs,\n",
    "    cifar_loss_fn, \n",
    "    cifar_train_validation_data.classes, \n",
    "    cifar_train_metrics,\n",
    "    cifar_validation_metrics,\n",
    "    device,\n",
    "    cifar_auxiliary_loss_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric({\"Training\": cifar_train_history, \"Validation\": cifar_validation_history}, metric=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric({\"Training\": cifar_train_history, \"Validation\": cifar_validation_history}, metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_test_metrics = cifar_train_metrics.clone()\n",
    "\n",
    "cifar_test_loss = validate_one_epoch(\n",
    "    cifar_model, \n",
    "    cifar_test_loader,\n",
    "    cifar_loss_fn,\n",
    "    num_classes,\n",
    "    cifar_test_metrics,\n",
    "    device,\n",
    "    \"Testing\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_test_history = {\n",
    "    \"loss\": [cifar_test_loss]\n",
    "} | {metric: [history.to(\"cpu\")] for metric, history in cifar_test_metrics.compute().items()}\n",
    "\n",
    "pretty_print_metrics(cifar_test_history, cifar_train_validation_data.classes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
